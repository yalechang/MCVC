import autograd.numpy as np
import autograd.scipy as sp
from autograd import grad

from minConf_PQN import minConf_PQN
from utils import unpackParam, projectParam, genConstraints, initParam

from objective import NegELBO, ELBO_terms

from scipy.optimize import check_grad
from multiprocessing.dummy import Pool as ThreadPool
from multiprocessing import cpu_count
import pickle
from sklearn.preprocessing import scale
from sklearn.decomposition import PCA
from sklearn.metrics import normalized_mutual_info_score as nmi

import time
import platform

def multiclust(param_init_list, prior, X, S, Ncon, G, M, K, options):
    """ This function generates the optimal solution given a set of random
    initializations
    """
    
    [N, D] = X.shape

    # define the objective f_param and gradient g_param
    f_param = lambda param: NegELBO(param, prior, X, S, Ncon, G, M, K)

    # apply autodifferentiation using python-autograd
    g_param = grad(f_param)
    
    # create function that returns both function value and gradient value
    funObj = lambda param: (f_param(param), g_param(param))
    # create projection function that projects a point into the constraint set
    funProj = lambda param: projectParam(param, N, D, G, M, K, lb=1e-12)
    # return the optimal solution given any initialization
    f_initParam = lambda param_init: minConf_PQN(funObj, param_init, funProj,\
            options=options)
    
    # run the algorithm multiple times
    num_init = len(param_init_list)
    result_set = []
    for idx_init in range(num_init):
        print "Initialization ID: " + str(idx_init)
        result_set.append(f_initParam(param_init_list[idx_init]))
    
    # select the optimal solution: (param_opt, fval_opt, funEvals_opt)
    fval_opt = np.infty
    for idx in np.arange(len(result_set)):
        item = result_set[idx]
        if item[1] < fval_opt:
            param_opt = item[0]            
            fval_opt = item[1]
            funEvals_opt = item[2]
            param_init_sel = param_init_list[idx]
    
    return (param_opt, fval_opt, funEvals_opt, param_init_sel)


if __name__ == "__main__":
    
    # load data matrix
    data_name = 'ThreeClusters'
    X = scale(np.loadtxt("data/ThreeClusters_X.csv", delimiter=','))
    Y_1 = np.loadtxt("data/ThreeClusters_Y_1.csv", delimiter=',')
    Y_2 = np.loadtxt("data/ThreeClusters_Y_2.csv", delimiter=',')
    K = 3
    
    [N, D] = X.shape
    # the number of pairwise constraints provided by each expert
    ncon = 400
    [num_ML, num_CL] = [ncon/2, ncon/2]
    # accuracy parameters of two groups of experts
    acc_G1 = [0.95, 0.90, 0.85, 0.80, 0.75]
    acc_G2 = [0.75, 0.80, 0.85, 0.90, 0.95]
    acc = [acc_G1, acc_G2]
    # compute the number of experts and set the maximal number of expert groups 
    M = len(acc_G1) + len(acc_G2)
    G = M/2

    # generate constraints
    [alpha_G1, beta_G1] = [acc_G1, acc_G1]
    [alpha_G2, beta_G2] = [acc_G2, acc_G2]
    prng = np.random.RandomState(100)
    # set random number generator
    S_G1 = genConstraints(prng, Y_1, alpha_G1, beta_G1, num_ML, num_CL, \
            start_expert=0, flag_same=True)
    S_G2 = genConstraints(prng, Y_2, alpha_G2, beta_G2, num_ML, num_CL, \
            start_expert=len(alpha_G1), flag_same=True)
    S = np.vstack((S_G1, S_G2))
    # compute the number of constraints generated by each expert
    Ncon = []
    for m in range(M):
        Ncon.append(num_ML+num_CL)

    
    # priors
    prior = {'mu_w':0, 'sigma_w': 1, 'mu_b':0, 'sigma_b':1,\
        'tau_a1':10, 'tau_a2':1, 'tau_b1':10, 'tau_b2':1, 'gamma':1}
    
    # parameter settings for the optimization
    options = {'optTol':1e-3, 'progTol':1e-6, 'maxIter':200, 'verbose':0}
    
    # create a set of initializations
    num_init = 20
    # parameter of Dirichlet distribution when randomly initializing phi
    dir_param = 1
    param_init_list = []
    for idx_init in range(num_init):
        prng = np.random.RandomState(1000+idx_init)
        param_init_list.append(initParam(prior, X, N,D,G,M,K,dir_param,prng))
    
    [param_opt, fval_opt, funEvals_opt, param_init_sel] = multiclust(\
            param_init_list, prior, X, S, Ncon, G, M, K, options)

    # unpack the optimal parameter vector
    [tau_a1, tau_a2, tau_b1, tau_b2, phi, tau_v1, tau_v2, mu_w, sigma_w,\
        mu_b, sigma_b] = unpackParam(param_opt, N, D, G, M, K)

    phi_label = np.zeros((M, 1))
    for m in np.arange(M):
        phi_label[m,0] = phi[m].argmax()


